<!DOCTYPE html><html lang="zh-Hans"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta name="keywords" content="最优化方法,信息检索,统计机器学习,深度学习,用户增长,A/B测试,多维度报表,转化漏斗"><meta name="description" content="这是刘鹏老师计算广告课程的笔记，这部分主要讲解计算广告相关的技术和方法，包括最优化方法，信息检索技术，统计机器学习和深度学习，以及如何实现用户增长的一些方法论"><meta name="author" content="ZhangHao"><meta name="viewport" content="width=device-width, initial-scale=0.5"><meta name="format-detection" content="telephone=no"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black"><title>计算广告|3.相关方法 - 张浩在路上</title><link rel="icon" href="/img/favicon.ico"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="dns-prefetch" href="https://hm.baidu.com"><script src="https://www.googletagmanager.com/gtag/js?id=UA-166608124-1" async=""></script><script>if (window.location.hostname !== 'localhost') {
  window.dataLayer = window.dataLayer || [];
  function gtag(){ dataLayer.push(arguments); }
  gtag('js', new Date());
  gtag('config', 'UA-166608124-1');
}</script><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement('script');
  hm.src = 'https://hm.baidu.com/hm.js?0c64a5657309290fd8f5efe33fcbcdb4';
  hm.async = true;

  var s = document.getElementsByTagName('script')[0];
  s.parentNode.insertBefore(hm, s);
})();</script><link rel="stylesheet" href="/css/post.css"><link rel="stylesheet" href="/css/header.css"><link rel="icon" href="/img/favicon.png"><meta name="generator" content="Hexo 5.4.0"><link rel="alternate" href="/atom.xml" title="张浩在路上" type="application/atom+xml">
</head><body>　　<nav class="navbar navbar-default navbar-fixed-top" style="opacity:.9;" role="navigation"><div class="container-fluid"><div class="navbar-header"><button class="navbar-toggle collapsed" type="button" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1"><span class="sr-only">Toggle navigation</span><span class="icon-bar"></span><span class="icon-bar"></span><span class="icon-bar"></span></button><a class="navbar-brand" href="/" _blank>张浩在路上</a></div><div class="navbar-collapse collapse" id="bs-example-navbar-collapse-1" style="height:1px;"><ul class="nav navbar-nav navbar-right"><li><a href="/" target="_self">首页</a></li><li><a href="/technology" target="_self">技术</a></li><li><a href="/monetization" target="_self">变现</a></li><li><a href="/thinking" target="_self">思考</a></li><li><a href="/about" target="_self">关于</a></li></ul></div></div></nav><div class="inner"><h1>计算广告|3.相关方法</h1><div id="toc"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9C%80%E4%BC%98%E5%8C%96optimization"><span class="toc-number">1.</span> <span class="toc-text"> 最优化Optimization</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF%E6%9C%80%E4%BC%98%E5%8C%96%E9%97%AE%E9%A2%98"><span class="toc-number">1.1.</span> <span class="toc-text"> 什么是最优化问题</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%97%A0%E7%BA%A6%E6%9D%9F%E4%BC%98%E5%8C%96%E9%97%AE%E9%A2%98%E4%B8%80%E8%88%AC%E6%80%9D%E8%B7%AF"><span class="toc-number">1.2.</span> <span class="toc-text"> 无约束优化问题一般思路</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%89%B9%E5%A4%84%E7%90%86%E6%A2%AF%E5%BA%A6%E6%B3%95%E7%9A%84%E9%97%AE%E9%A2%98%E4%B8%8E%E6%8B%9F%E7%89%9B%E9%A1%BF%E6%B3%95"><span class="toc-number">1.3.</span> <span class="toc-text"> 批处理梯度法的问题与拟牛顿法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#bfgs%E5%92%8Cl-bfgs%E6%96%B9%E6%B3%95"><span class="toc-number">1.4.</span> <span class="toc-text"> BFGS和L-BFGS方法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#trust-region%E6%96%B9%E6%B3%95"><span class="toc-number">1.5.</span> <span class="toc-text"> Trust-Region方法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B8%A6%E7%BA%A6%E6%9D%9F%E4%BC%98%E5%8C%96%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E6%B3%95"><span class="toc-number">1.6.</span> <span class="toc-text"> 带约束优化：拉格朗日法</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BF%A1%E6%81%AF%E6%A3%80%E7%B4%A2information-retrieval"><span class="toc-number">2.</span> <span class="toc-text"> 信息检索Information Retrieval</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%96%87%E6%A1%A3%E7%9A%84%E8%A1%A8%E7%A4%BA%E4%B8%8E%E7%9B%B8%E4%BC%BC%E5%BA%A6%E9%87%8F"><span class="toc-number">2.1.</span> <span class="toc-text"> 文档的表示与相似度量</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%80%92%E6%8E%92%E7%B4%A2%E5%BC%95"><span class="toc-number">2.2.</span> <span class="toc-text"> 倒排索引</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BB%9F%E8%AE%A1%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0statistical-machine-learning"><span class="toc-number">3.</span> <span class="toc-text"> 统计机器学习Statistical Machine Learning</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%AD%A6%E4%B9%A0"><span class="toc-number">3.1.</span> <span class="toc-text"> 贝叶斯学习</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%8C%87%E6%95%B0%E6%97%8F%E5%88%86%E5%B8%83"><span class="toc-number">3.2.</span> <span class="toc-text"> 指数族分布</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%8C%87%E6%95%B0%E6%97%8F%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%AD%A6%E4%B9%A0"><span class="toc-number">3.3.</span> <span class="toc-text"> 指数族贝叶斯学习</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%8C%87%E6%95%B0%E6%97%8F%E5%88%86%E5%B8%83%E4%BA%8C"><span class="toc-number">3.4.</span> <span class="toc-text"> 指数族分布（二）</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0deep-learning"><span class="toc-number">4.</span> <span class="toc-text"> 深度学习Deep Learning</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%98%AF%E4%BB%80%E4%B9%88"><span class="toc-number">4.1.</span> <span class="toc-text"> 深度学习是什么？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%85%A8%E8%BF%9E%E6%8E%A5%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BAmulti-layer-perceptron-mlp"><span class="toc-number">4.2.</span> <span class="toc-text"> 全连接多层感知机（Multi-layer Perceptron, MLP）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%B7%A5%E7%A8%8B%E6%9C%AC%E8%B4%A8"><span class="toc-number">4.3.</span> <span class="toc-text"> 深度学习的工程本质</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%87%A0%E7%A7%8D%E9%87%8D%E8%A6%81%E7%9A%84%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84"><span class="toc-number">4.4.</span> <span class="toc-text"> 几种重要的神经网络结构</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%BC%98%E5%8C%96%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD"><span class="toc-number">4.5.</span> <span class="toc-text"> 深度学习优化基础设施</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E8%BF%90%E8%90%A5%E4%B8%89%E6%9D%BF%E6%96%A7-%E7%94%A8%E6%88%B7%E5%A2%9E%E9%95%BF"><span class="toc-number">5.</span> <span class="toc-text"> 数据运营三板斧 – 用户增长</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%94%A8%E6%88%B7%E5%A2%9E%E9%95%BF%E7%9A%84%E5%9F%BA%E7%A1%80%E7%94%A8%E6%88%B7%E8%BD%AC%E5%8C%96%E6%BC%8F%E6%96%97"><span class="toc-number">5.1.</span> <span class="toc-text"> 用户增长的基础：用户转化漏斗</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%89%BE%E5%88%B0%E5%A2%9E%E9%95%BF%E7%9A%84%E9%9A%9C%E7%A2%8D%E5%A4%9A%E7%BB%B4%E5%BA%A6%E6%8A%A5%E8%A1%A8%E5%88%86%E6%9E%90"><span class="toc-number">5.2.</span> <span class="toc-text"> 找到增长的障碍：多维度报表分析</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%A9%B1%E5%8A%A8%E6%96%B0%E4%BA%A7%E5%93%81%E7%89%B9%E5%BE%81%E5%88%A9%E7%94%A8ab%E6%B5%8B%E8%AF%95"><span class="toc-number">5.3.</span> <span class="toc-text"> 驱动新产品特征：利用A&#x2F;B测试</span></a></li></ol></li></ol></div><h2 id="最优化optimization"><a class="markdownIt-Anchor" href="#最优化optimization"></a> 最优化Optimization</h2>
<h3 id="什么是最优化问题"><a class="markdownIt-Anchor" href="#什么是最优化问题"></a> 什么是最优化问题</h3>
<p>无约束最优化问题：</p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>m</mi><mi>i</mi><mi>n</mi><mi>f</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">minf(x) 
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">m</span><span class="mord mathdefault">i</span><span class="mord mathdefault">n</span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mclose">)</span></span></span></span></span></p>
<p>带约束最优化问题：</p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mtable rowspacing="0.24999999999999992em" columnalign="right" columnspacing=""><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mi>m</mi><mi>i</mi><mi>n</mi><mi>f</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mi>s</mi><mi mathvariant="normal">.</mi><mi>t</mi><mi mathvariant="normal">.</mi><mtext mathvariant="bold">g</mtext><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>⩽</mo><mn>0</mn><mo separator="true">,</mo><mtext mathvariant="bold">h</mtext><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mn>0</mn></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{aligned}
min f(x)  \\
s.t. \textbf{g}(x)\leqslant 0,\textbf{h}(x)=0
\end{aligned}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:3.0000000000000004em;vertical-align:-1.2500000000000002em;"></span><span class="mord"><span class="mtable"><span class="col-align-r"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.7500000000000002em;"><span style="top:-3.91em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault">m</span><span class="mord mathdefault">i</span><span class="mord mathdefault">n</span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mclose">)</span></span></span><span style="top:-2.41em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault">s</span><span class="mord">.</span><span class="mord mathdefault">t</span><span class="mord">.</span><span class="mord text"><span class="mord textbf">g</span></span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel amsrm">⩽</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord text"><span class="mord textbf">h</span></span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.2500000000000002em;"><span></span></span></span></span></span></span></span></span></span></span></span></p>
<h3 id="无约束优化问题一般思路"><a class="markdownIt-Anchor" href="#无约束优化问题一般思路"></a> 无约束优化问题一般思路</h3>
<p>目标函数不可/不易求导</p>
<ul>
<li>下降单纯形法（Ameoba变形虫法）</li>
</ul>
<p>目标函数易求导</p>
<ul>
<li>梯度下降法</li>
<li>批处理模式：训练集上的梯度分解为各个样本梯度的和，可以并行实现。</li>
<li>串行模式：随机梯度下降法（Stochastic Gradient Descent，SGD）【好用】</li>
</ul>
<h3 id="批处理梯度法的问题与拟牛顿法"><a class="markdownIt-Anchor" href="#批处理梯度法的问题与拟牛顿法"></a> 批处理梯度法的问题与拟牛顿法</h3>
<p>梯度法zigzag更新过程</p>
<ul>
<li>等高线和梯度垂直，因为等高线的形状是压扁的形状，所以会来回的跳，性能不好。</li>
</ul>
<p>牛顿法</p>
<ul>
<li>不仅考虑一阶导，还考虑二阶导。但是Hession阵可能不正定。</li>
</ul>
<p>拟牛顿法</p>
<ul>
<li>用近似但正定的Hession阵确保稳定求解</li>
</ul>
<span id="more"></span>
<h3 id="bfgs和l-bfgs方法"><a class="markdownIt-Anchor" href="#bfgs和l-bfgs方法"></a> BFGS和L-BFGS方法</h3>
<p>BFGS（Broyden，Fletcher，Oldfarb，and Shanno）</p>
<ul>
<li>拟牛顿法是一种，用函数值和特征的变化量来近似Hession矩阵，以保证正定性，并减少计算量。</li>
<li>Hession集合公式（空间复杂度为N方）</li>
</ul>
<p>L（Limited memory）- BFGS</p>
<ul>
<li>将Hession逆用{n*k}*{k*k}*{k*n}的方式近似【矩阵分解】</li>
<li>空间复杂度为n*k</li>
</ul>
<h3 id="trust-region方法"><a class="markdownIt-Anchor" href="#trust-region方法"></a> Trust-Region方法</h3>
<p>方法思想</p>
<ul>
<li>不近似Hession阵，但每次迭代将自变量限制在临域内</li>
<li>先步长，后方向</li>
</ul>
<p>上述子问题虽非凸优化，但是满足KKT条件</p>
<p>对于LR模型收敛速度经常好于L-BFGS</p>
<h3 id="带约束优化拉格朗日法"><a class="markdownIt-Anchor" href="#带约束优化拉格朗日法"></a> 带约束优化：拉格朗日法</h3>
<p>原问题（Primary Problem）==&gt; 拉格朗日对偶函数(Lagrangian dual function) ==&gt; 对偶问题(Dual problem)</p>
<h2 id="信息检索information-retrieval"><a class="markdownIt-Anchor" href="#信息检索information-retrieval"></a> 信息检索Information Retrieval</h2>
<h3 id="文档的表示与相似度量"><a class="markdownIt-Anchor" href="#文档的表示与相似度量"></a> 文档的表示与相似度量</h3>
<p>词袋（Bag of Words，BoW）表示</p>
<ul>
<li>用关键词TFIDF组成的矢量来表示文档。</li>
</ul>
<p>TF-IDF</p>
<ul>
<li>TF（term frequency）： 某文档中词出现的次数</li>
<li>IDF（inverse document frequency）：总文档数/某个词出现的文档数，然后取log</li>
</ul>
<p>向量空间模型</p>
<ul>
<li>用余弦距离来衡量两个文档的相似度</li>
</ul>
<h3 id="倒排索引"><a class="markdownIt-Anchor" href="#倒排索引"></a> 倒排索引</h3>
<p>文档集</p>
<ul>
<li>D1=“谷歌地图之父跳槽Facebook”</li>
<li>D2=“谷歌地图创始人拉斯离开谷歌加盟Facebook”</li>
<li>D3=“谷歌地图创始人跳槽Facebook与Wave项目取消有关”</li>
<li>D4=“谷歌地图创始人拉斯加盟社交网络Facebook”</li>
</ul>
<p>关键词（Term）</p>
<ul>
<li>{谷歌，地图，之父，跳槽，Facebook，……}</li>
</ul>
<p>倒排链</p>
<ul>
<li>谷歌-&gt;{D1，D2，D3，D4}，地图-&gt;{D1,D2,D3,D4},之父-&gt;{D1,D3,D4},跳槽-&gt;{D1,D3},Facebook-&gt;{D1,D2,D3,D4},……</li>
</ul>
<h2 id="统计机器学习statistical-machine-learning"><a class="markdownIt-Anchor" href="#统计机器学习statistical-machine-learning"></a> 统计机器学习Statistical Machine Learning</h2>
<h3 id="贝叶斯学习"><a class="markdownIt-Anchor" href="#贝叶斯学习"></a> 贝叶斯学习</h3>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><mi mathvariant="normal">Θ</mi><mi mathvariant="normal">∣</mi><mi>X</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>X</mi><mi mathvariant="normal">∣</mi><mi mathvariant="normal">Θ</mi><mo stretchy="false">)</mo><mi>P</mi><mo stretchy="false">(</mo><mi mathvariant="normal">Θ</mi><mo stretchy="false">)</mo></mrow><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo></mrow></mfrac></mrow><annotation encoding="application/x-tex">P(\Theta | X ) = \frac{P(X | \Theta)P(\Theta)}{P(X)}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord">Θ</span><span class="mord">∣</span><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.363em;vertical-align:-0.936em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="mclose">)</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="mord">∣</span><span class="mord">Θ</span><span class="mclose">)</span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord">Θ</span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p>
<p>贝叶斯公式</p>
<ul>
<li>统计机器学习最核心的概念和公式。</li>
<li>频率学派 VS 贝叶斯学派</li>
<li>X是观测的变量，Theta是要估计的参数。</li>
<li>$P(\Theta | X ) $ 是后验概率Posterior，所有的分类都是追求后验概率最大的原则。</li>
<li><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>X</mi><mi mathvariant="normal">∣</mi><mi mathvariant="normal">Θ</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">P(X | \Theta)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="mord">∣</span><span class="mord">Θ</span><span class="mclose">)</span></span></span></span>是likelihood(已知是黑人，黑人拥有黑色皮肤的概率)，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><mi mathvariant="normal">Θ</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">P(\Theta)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord">Θ</span><span class="mclose">)</span></span></span></span>是prior（黑人在中国出现的概率）.</li>
<li><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">P(X)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="mclose">)</span></span></span></span> 是evidence</li>
<li>贝叶斯的核心是认为所有参数都是不确定的。</li>
</ul>
<p>若干模型估计方法</p>
<h3 id="指数族分布"><a class="markdownIt-Anchor" href="#指数族分布"></a> 指数族分布</h3>
<p>归一化形式：<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>x</mi><mi mathvariant="normal">∣</mi><mi mathvariant="normal">Θ</mi><mo stretchy="false">)</mo><mo>=</mo><mi>h</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mi>g</mi><mo stretchy="false">(</mo><mi mathvariant="normal">Θ</mi><mo stretchy="false">)</mo><mi>e</mi><mi>x</mi><mi>p</mi><mrow><mo fence="true">{</mo><msup><mi mathvariant="normal">Θ</mi><mi>T</mi></msup><mi>u</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo fence="true">}</mo></mrow></mrow><annotation encoding="application/x-tex">P(x|\Theta)=h(x)g(\Theta)exp\left \{ \Theta^Tu(x) \right \}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mord">∣</span><span class="mord">Θ</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.20001em;vertical-align:-0.35001em;"></span><span class="mord mathdefault">h</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mclose">)</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mopen">(</span><span class="mord">Θ</span><span class="mclose">)</span><span class="mord mathdefault">e</span><span class="mord mathdefault">x</span><span class="mord mathdefault">p</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size1">{</span></span><span class="mord"><span class="mord">Θ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span><span class="mord mathdefault">u</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mclose">)</span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size1">}</span></span></span></span></span></span></p>
<p>若干重要指数族分布</p>
<h3 id="指数族贝叶斯学习"><a class="markdownIt-Anchor" href="#指数族贝叶斯学习"></a> 指数族贝叶斯学习</h3>
<p>共轭先验：使先验分布与后验分布形式一致的先验分布</p>
<p>指数族分布共轭先验，一般形式：</p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>p</mi><mo stretchy="false">(</mo><mi mathvariant="normal">Θ</mi><mi mathvariant="normal">∣</mi><mi>η</mi><mo stretchy="false">)</mo><mo>=</mo><mi>e</mi><mi>x</mi><mi>p</mi><mrow><mo fence="true">{</mo><msup><mi>χ</mi><mi>T</mi></msup><mi mathvariant="normal">Θ</mi><mo>−</mo><mi>v</mi><mi>g</mi><mo stretchy="false">(</mo><mi mathvariant="normal">Θ</mi><mo stretchy="false">)</mo><mo>−</mo><mi>b</mi><mo stretchy="false">(</mo><mi>χ</mi><mo separator="true">,</mo><mi>v</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo fence="true">}</mo></mrow></mrow><annotation encoding="application/x-tex">p(\Theta|\eta)=exp\left \{ \chi ^{T} \Theta-vg(\Theta)-b(\chi ,v))) \right \}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">p</span><span class="mopen">(</span><span class="mord">Θ</span><span class="mord">∣</span><span class="mord mathdefault" style="margin-right:0.03588em;">η</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.2413409999999998em;vertical-align:-0.35001em;"></span><span class="mord mathdefault">e</span><span class="mord mathdefault">x</span><span class="mord mathdefault">p</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size1">{</span></span><span class="mord"><span class="mord mathdefault">χ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8913309999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span></span><span class="mord">Θ</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">v</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mopen">(</span><span class="mord">Θ</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathdefault">b</span><span class="mopen">(</span><span class="mord mathdefault">χ</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">v</span><span class="mclose">)</span><span class="mclose">)</span><span class="mclose">)</span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size1">}</span></span></span></span></span></span></span></p>
<p>其中<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>η</mi><mo>=</mo><mrow><mo fence="true">{</mo><mi>χ</mi><mo separator="true">,</mo><mi>v</mi><mo fence="true">}</mo></mrow></mrow><annotation encoding="application/x-tex">\eta=\left \{ \chi, v \right \}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">η</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">{</span><span class="mord mathdefault">χ</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">v</span><span class="mclose delimcenter" style="top:0em;">}</span></span></span></span></span>为超参数（hyperperameter）</p>
<p>指数族后验部分的超参数：</p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mover accent="true"><mi>χ</mi><mo>~</mo></mover><mo>=</mo><mi>χ</mi><mo>+</mo><munderover><mo>∑</mo><mi>N</mi><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow></munderover><mi>u</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\tilde{\chi} = \chi + \sum_{N}^{i=1}u(x_i)
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8622999999999998em;vertical-align:-0.19444em;"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6678599999999999em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault">χ</span></span></span><span style="top:-3.35em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.19444em;">~</span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.19444em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.7777700000000001em;vertical-align:-0.19444em;"></span><span class="mord mathdefault">χ</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:3.106005em;vertical-align:-1.294336em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8116690000000002em;"><span style="top:-1.855664em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.10903em;">N</span></span></span></span><span style="top:-3.050005em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3000050000000005em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.294336em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">u</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mover accent="true"><mi>v</mi><mo>~</mo></mover><mo>=</mo><mi>v</mi><mo>+</mo><mi>N</mi></mrow><annotation encoding="application/x-tex">\tilde{v} = v + N
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6678599999999999em;vertical-align:0em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6678599999999999em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">v</span></span></span><span style="top:-3.35em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.22222em;">~</span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.66666em;vertical-align:-0.08333em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">v</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.10903em;">N</span></span></span></span></span></p>
<h3 id="指数族分布二"><a class="markdownIt-Anchor" href="#指数族分布二"></a> 指数族分布（二）</h3>
<p>最大似然估计：<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo>−</mo><mi mathvariant="normal">▽</mi><mi>l</mi><mi>n</mi><mtext mathvariant="bold">g</mtext><mo stretchy="false">(</mo><msub><mi>θ</mi><mrow><mi>M</mi><mi>L</mi></mrow></msub><mo stretchy="false">)</mo><mo>=</mo><mfrac><mn>1</mn><mi>N</mi></mfrac><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></msubsup><mi>u</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">-\triangledown ln \textbf{g}(\theta_{ML} )=\frac{1}{N}\sum_{i=1}^{N}u(x_i)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">−</span><span class="mord amsrm">▽</span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault">n</span><span class="mord text"><span class="mord textbf">g</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.10903em;">M</span><span class="mord mathdefault mtight">L</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.326231em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.845108em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.10903em;">N</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.981231em;"><span style="top:-2.40029em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.10903em;">N</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.29971000000000003em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">u</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></p>
<p>混合模型：<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>x</mi><mi mathvariant="normal">∣</mi><mi>ω</mi><mo separator="true">,</mo><mi mathvariant="normal">Θ</mi><mo stretchy="false">)</mo><mo>=</mo><msubsup><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>K</mi></msubsup><msub><mi>w</mi><mi>k</mi></msub><mi>h</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mi>g</mi><mo stretchy="false">(</mo><msub><mi mathvariant="normal">Θ</mi><mi>k</mi></msub><mo stretchy="false">)</mo><mi>e</mi><mi>x</mi><mi>p</mi><mrow><mo fence="true">{</mo><msubsup><mi mathvariant="normal">Θ</mi><mi>k</mi><mi>T</mi></msubsup><mi>u</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo fence="true">}</mo></mrow></mrow><annotation encoding="application/x-tex">P(x|\omega , \Theta)=\sum_{k=1}^{K}w_kh(x)g(\Theta_k)exp\left \{ \Theta_{k}^{T}u(x) \right \}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mord">∣</span><span class="mord mathdefault" style="margin-right:0.03588em;">ω</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">Θ</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.331241em;vertical-align:-0.35001em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.981231em;"><span style="top:-2.40029em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.07153em;">K</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.29971000000000003em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord mathdefault">h</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mclose">)</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mopen">(</span><span class="mord"><span class="mord">Θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mord mathdefault">e</span><span class="mord mathdefault">x</span><span class="mord mathdefault">p</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size1">{</span></span><span class="mord"><span class="mord">Θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-2.4168920000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">T</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2831079999999999em;"><span></span></span></span></span></span></span><span class="mord mathdefault">u</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mclose">)</span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size1">}</span></span></span></span></span></span></p>
<ul>
<li>EM算法</li>
</ul>
<h2 id="深度学习deep-learning"><a class="markdownIt-Anchor" href="#深度学习deep-learning"></a> 深度学习Deep Learning</h2>
<h3 id="深度学习是什么"><a class="markdownIt-Anchor" href="#深度学习是什么"></a> 深度学习是什么？</h3>
<p>基于规则的系统</p>
<ul>
<li>img of 8 --&gt; 人工设计程序 --&gt; num of 8</li>
</ul>
<p>传统机器学习</p>
<ul>
<li>img of 8 --&gt; 人工设计特征 --&gt; 将特征映射到结果 --&gt; num of 8</li>
</ul>
<p>深度学习(表示学习)</p>
<ul>
<li>img of 8 --&gt; 自动提取特征 --&gt; 将特征映射到结果 --&gt; num of 8</li>
<li>img of 8 --&gt; 原始特征 --&gt; 额外的层和抽象特征 --&gt; 将特征映射到结果 --&gt; num of 8</li>
</ul>
<h3 id="全连接多层感知机multi-layer-perceptron-mlp"><a class="markdownIt-Anchor" href="#全连接多层感知机multi-layer-perceptron-mlp"></a> 全连接多层感知机（Multi-layer Perceptron, MLP）</h3>
<h3 id="深度学习的工程本质"><a class="markdownIt-Anchor" href="#深度学习的工程本质"></a> 深度学习的工程本质</h3>
<p>浅层模型与深度模型</p>
<ul>
<li>深度模型比浅层模型表示能力更强</li>
</ul>
<p>优化方法是关键</p>
<ul>
<li>找到了GPU这条优化方法</li>
</ul>
<p>数据的作用</p>
<ul>
<li>深度学习和大数据关系非常紧密</li>
</ul>
<h3 id="几种重要的神经网络结构"><a class="markdownIt-Anchor" href="#几种重要的神经网络结构"></a> 几种重要的神经网络结构</h3>
<p>CNN（Convolutional Neural Networks, 卷积神经网络）</p>
<ul>
<li>采样层-&gt;卷积层-&gt;采样层-&gt;全连接层MLP</li>
<li>参数共享</li>
<li>图像领域</li>
</ul>
<p>RNN（Recurrent Neural Networks，递归神经网络）</p>
<ul>
<li>用递归的方式设计网络结构</li>
<li>sequence到sequence的学习</li>
<li>语言领域</li>
<li>LSTM（Long-Short Term Memory，长短期记忆）是一种时间递归神经网络(RNN)</li>
</ul>
<p>GAN（Generative Adversarial Network，生成对抗网络）</p>
<h3 id="深度学习优化基础设施"><a class="markdownIt-Anchor" href="#深度学习优化基础设施"></a> 深度学习优化基础设施</h3>
<p>GPU方案</p>
<ul>
<li>并行渲染屏幕上每个像素点，与并行计算各神经元很相似</li>
<li>与CPU方案相比，可以加速数倍乃至十数倍</li>
</ul>
<p>并行计算方法</p>
<ul>
<li>SGD过程可以分解到多台机器上进行，分别更新参数</li>
<li>可以采用parameter server的计算框架，水平扩展性强</li>
</ul>
<p>开源框架</p>
<ul>
<li>Tensorflow，Caffe，Mxnet，可以一定程度上忽略硬件</li>
</ul>
<h2 id="数据运营三板斧-用户增长"><a class="markdownIt-Anchor" href="#数据运营三板斧-用户增长"></a> 数据运营三板斧 – 用户增长</h2>
<h3 id="用户增长的基础用户转化漏斗"><a class="markdownIt-Anchor" href="#用户增长的基础用户转化漏斗"></a> 用户增长的基础：用户转化漏斗</h3>
<p>用户转化漏斗示例</p>
<ul>
<li>移动用户获取：下载-&gt;激活-&gt;留存-&gt;时长</li>
<li>电商用户转化：到达商品页-&gt;加入购物车-&gt;完成订单-&gt;交易确认</li>
</ul>
<p>漏斗的设计原则与作用</p>
<ul>
<li>原则：整个漏斗过程用于优化一个唯一的目标</li>
<li>作用：将该目标分解为若干比率的乘积，便于发现问题并优化</li>
<li>示例：总用户时长 = 下载量 X 激活率 X 留存率 X 平均用户时长</li>
</ul>
<p>转化漏斗相关常见度量</p>
<ul>
<li>转化率 - 激活数与点击数的比</li>
<li>「次日/七日/月」留存率 - 某日激活的用户中，「次日/七日/月」后活跃的用户占比</li>
<li>「日/月」活跃用户（DAU，MAU）- 每「日/月」活跃的独立用户数</li>
<li>用户时长 - 每个活跃用户平均消耗的时间</li>
</ul>
<h3 id="找到增长的障碍多维度报表分析"><a class="markdownIt-Anchor" href="#找到增长的障碍多维度报表分析"></a> 找到增长的障碍：多维度报表分析</h3>
<p>通过漏斗发现问题</p>
<ul>
<li>某页游用户转化漏斗：</li>
<li>到达（5130）–19.1%–&gt;注册（980）–14.0%–&gt; 参与（431）–83.0%–&gt; 充值</li>
<li>注册率偏低，应该进一步分析？</li>
</ul>
<p>在多维度报表中找到症结</p>
<ul>
<li>注册率19.1%  – IE(25.1%),Chrome(3.5%),FireFox(22.7%)</li>
</ul>
<p>数据魔方（Data Cube）</p>
<ul>
<li>什么是数据魔方？ 1）用户可以较灵活选择维度组合，得到定制化报表。2）为人工决策提供便利</li>
<li>技术方案：OLAP数据库</li>
<li>开源方案：Saiku+MySQL</li>
</ul>
<h3 id="驱动新产品特征利用ab测试"><a class="markdownIt-Anchor" href="#驱动新产品特征利用ab测试"></a> 驱动新产品特征：利用A/B测试</h3>
<p>为什么需要A/B测试？</p>
<ul>
<li>多维情况下，魔方里大部分区域数据非常稀疏。极端情形：对于新Feature，需要主动分配测试流量</li>
<li>某维度上的两个选项（例如两个不同的模型），数据并不是完全可比</li>
<li>因此，我们需要一个主动的A/B测试框架，以便：1）主动分配流量给新的产品特征；2）保证对比实验的各组在数据上完全可比；3）尽可能在同样的流量规模上容纳更多的实验。</li>
</ul>
<p>A/B测试并不是万能的</p>
<ul>
<li>用户产品过于依赖数据会丧失对关键创新的把握。- 汽车无法从“跑得更快的马”进化而来</li>
<li>多数情况下，需要测试的可行组合太多，必须先经过人的筛选，或更复杂的E&amp;E策略。- 每天数十万的新闻，那些有可能最受用户欢迎？</li>
<li>博弈性场景无法通过A/B测试获得可靠性结论</li>
<li>A/B测试最适合的场景：理性产品、被动反应场景</li>
</ul>
<!-- lincense--><div class="license-wrapper"><p><span>文章作者:</span><a href="https://imzhanghao.com">ZhangHao</a></p><p><span>文章链接:</span><a href="https://imzhanghao.com/2020/06/12/computing-advertising-3-related-knowledge/">https://imzhanghao.com/2020/06/12/computing-advertising-3-related-knowledge/</a></p><p><span>版权声明:</span><span>All articles in this blog are licensed under <a rel="license noopener" target="_blank" href="https://creativecommons.org/licenses/by-nc-nd/3.0">CC BY-NC-SA 3.0</a> unless stating additionally.</span></p></div><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4128258433761966" data-ad-slot="1528926940" data-ad-format="auto" data-full-width-responsive="true"></ins><script>(adsbygoogle = window.adsbygoogle || []).push({});
</script><hr><p><span>↶ </span><a href="/">返回首页</a><span></span></p></div><script src="/js/jquery.min.js"></script><script src="/js/main.js"></script><script src="/js/bootstrap.min.js"></script><link href="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.css" rel="stylesheet" type="text/css"><link href="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/contrib/copy-tex.css" rel="stylesheet" type="text/css"><script src="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/contrib/copy-tex.min.js"></script></body></html>